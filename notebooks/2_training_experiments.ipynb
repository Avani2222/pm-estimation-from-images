{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9c80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe6a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/avanigupta/pm-estimation-from-images/data/final_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8857441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "df[\"Hour\"] = pd.to_numeric(df[\"Hour\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d040a4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location              object\n",
       "Filename              object\n",
       "Year                   int64\n",
       "Month                  int64\n",
       "Day                    int64\n",
       "Hour                 float64\n",
       "AQI                    int64\n",
       "PM2.5                float64\n",
       "PM10                 float64\n",
       "O3                   float64\n",
       "CO                   float64\n",
       "SO2                  float64\n",
       "NO2                  float64\n",
       "AQI_Class             object\n",
       "AQI_Class_encoded      int64\n",
       "exists                  bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e726cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/avanigupta/pm-estimation-from-images/models/label_scaler.save']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['AQI','PM2.5','PM10','O3','CO','SO2','NO2']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit only on label columns\n",
    "df[label_cols] = scaler.fit_transform(df[label_cols])\n",
    "\n",
    "# Save scaler for inference later\n",
    "joblib.dump(scaler, \"/Users/avanigupta/pm-estimation-from-images/models/label_scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da512304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirQualityDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_cols = ['AQI','PM2.5','PM10','O3','CO','SO2','NO2']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        filename = row[\"Filename\"].strip()  # remove leading/trailing spaces\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"File not found: {img_path}\")\n",
    "            return None  # optionally skip this sample\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Convert labels to float\n",
    "        labels = torch.tensor(\n",
    "            row[self.label_cols].astype(float).values,\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        return img, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46940132",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8068c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/Users/avanigupta/pm-estimation-from-images/data/archive/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/All_img\"  # update if needed\n",
    "\n",
    "dataset = AirQualityDataset(\n",
    "    df=df,\n",
    "    img_dir=img_dir,\n",
    "    transform=img_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3a7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, test_size]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c59a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96364ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(\n",
    "            weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        model.fc = nn.Linear(512, 7)\n",
    "\n",
    "    elif model_name == \"resnet34\":\n",
    "        model = models.resnet34(\n",
    "            weights=models.ResNet34_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        model.fc = nn.Linear(512, 7)\n",
    "\n",
    "    elif model_name == \"mobilenet_v2\":\n",
    "        model = models.mobilenet_v2(\n",
    "            weights=models.MobileNet_V2_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        model.classifier[1] = nn.Linear(\n",
    "            model.classifier[1].in_features, 7\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model name\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec9eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"resnet34\",\n",
    "    \"resnet18\",\n",
    "    \"mobilenet_v2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca6d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_dir = \"/Users/avanigupta/pm-estimation-from-images/models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "torch.save(test_dataset, \"/Users/avanigupta/pm-estimation-from-images/models/test_dataset.pt\")\n",
    "num_epochs = 25\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba77463",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05817f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/Users/avanigupta/pm-estimation-from-images/models\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a8aa118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: resnet34\n",
      "yes\n",
      "[resnet34] Epoch 1: Loss = 0.0270\n",
      "yes\n",
      "[resnet34] Epoch 2: Loss = 0.0052\n",
      "yes\n",
      "[resnet34] Epoch 3: Loss = 0.0036\n",
      "yes\n",
      "[resnet34] Epoch 4: Loss = 0.0030\n",
      "yes\n",
      "[resnet34] Epoch 5: Loss = 0.0026\n",
      "yes\n",
      "[resnet34] Epoch 6: Loss = 0.0022\n",
      "yes\n",
      "[resnet34] Epoch 7: Loss = 0.0019\n",
      "yes\n",
      "[resnet34] Epoch 8: Loss = 0.0017\n",
      "yes\n",
      "[resnet34] Epoch 9: Loss = 0.0014\n",
      "yes\n",
      "[resnet34] Epoch 10: Loss = 0.0014\n",
      "yes\n",
      "[resnet34] Epoch 11: Loss = 0.0014\n",
      "yes\n",
      "[resnet34] Epoch 12: Loss = 0.0013\n",
      "yes\n",
      "[resnet34] Epoch 13: Loss = 0.0012\n",
      "yes\n",
      "[resnet34] Epoch 14: Loss = 0.0011\n",
      "yes\n",
      "[resnet34] Epoch 15: Loss = 0.0011\n",
      "yes\n",
      "[resnet34] Epoch 16: Loss = 0.0011\n",
      "yes\n",
      "[resnet34] Epoch 17: Loss = 0.0010\n",
      "yes\n",
      "[resnet34] Epoch 18: Loss = 0.0010\n",
      "yes\n",
      "[resnet34] Epoch 19: Loss = 0.0012\n",
      "yes\n",
      "[resnet34] Epoch 20: Loss = 0.0010\n",
      "yes\n",
      "[resnet34] Epoch 21: Loss = 0.0010\n",
      "yes\n",
      "[resnet34] Epoch 22: Loss = 0.0008\n",
      "yes\n",
      "[resnet34] Epoch 23: Loss = 0.0008\n",
      "yes\n",
      "[resnet34] Epoch 24: Loss = 0.0010\n",
      "yes\n",
      "[resnet34] Epoch 25: Loss = 0.0009\n",
      "[resnet34] Test MSE (scaled): 0.0014\n",
      "ðŸ’¾ Saved model â†’ /Users/avanigupta/pm-estimation-from-images/models/resnet34_aqi.pth\n",
      "\n",
      "Training model: resnet18\n",
      "yes\n",
      "[resnet18] Epoch 1: Loss = 0.0279\n",
      "yes\n",
      "[resnet18] Epoch 2: Loss = 0.0060\n",
      "yes\n",
      "[resnet18] Epoch 3: Loss = 0.0044\n",
      "yes\n",
      "[resnet18] Epoch 4: Loss = 0.0038\n",
      "yes\n",
      "[resnet18] Epoch 5: Loss = 0.0032\n",
      "yes\n",
      "[resnet18] Epoch 6: Loss = 0.0025\n",
      "yes\n",
      "[resnet18] Epoch 7: Loss = 0.0024\n",
      "yes\n",
      "[resnet18] Epoch 8: Loss = 0.0023\n",
      "yes\n",
      "[resnet18] Epoch 9: Loss = 0.0021\n",
      "yes\n",
      "[resnet18] Epoch 10: Loss = 0.0019\n",
      "yes\n",
      "[resnet18] Epoch 11: Loss = 0.0018\n",
      "yes\n",
      "[resnet18] Epoch 12: Loss = 0.0017\n",
      "yes\n",
      "[resnet18] Epoch 13: Loss = 0.0015\n",
      "yes\n",
      "[resnet18] Epoch 14: Loss = 0.0014\n",
      "yes\n",
      "[resnet18] Epoch 15: Loss = 0.0014\n",
      "yes\n",
      "[resnet18] Epoch 16: Loss = 0.0014\n",
      "yes\n",
      "[resnet18] Epoch 17: Loss = 0.0014\n",
      "yes\n",
      "[resnet18] Epoch 18: Loss = 0.0012\n",
      "yes\n",
      "[resnet18] Epoch 19: Loss = 0.0012\n",
      "yes\n",
      "[resnet18] Epoch 20: Loss = 0.0011\n",
      "yes\n",
      "[resnet18] Epoch 21: Loss = 0.0011\n",
      "yes\n",
      "[resnet18] Epoch 22: Loss = 0.0010\n",
      "yes\n",
      "[resnet18] Epoch 23: Loss = 0.0010\n",
      "yes\n",
      "[resnet18] Epoch 24: Loss = 0.0009\n",
      "yes\n",
      "[resnet18] Epoch 25: Loss = 0.0009\n",
      "[resnet18] Test MSE (scaled): 0.0015\n",
      "ðŸ’¾ Saved model â†’ /Users/avanigupta/pm-estimation-from-images/models/resnet18_aqi.pth\n",
      "\n",
      "Training model: mobilenet_v2\n",
      "yes\n",
      "[mobilenet_v2] Epoch 1: Loss = 0.0491\n",
      "yes\n",
      "[mobilenet_v2] Epoch 2: Loss = 0.0160\n",
      "yes\n",
      "[mobilenet_v2] Epoch 3: Loss = 0.0095\n",
      "yes\n",
      "[mobilenet_v2] Epoch 4: Loss = 0.0073\n",
      "yes\n",
      "[mobilenet_v2] Epoch 5: Loss = 0.0062\n",
      "yes\n",
      "[mobilenet_v2] Epoch 6: Loss = 0.0050\n",
      "yes\n",
      "[mobilenet_v2] Epoch 7: Loss = 0.0043\n",
      "yes\n",
      "[mobilenet_v2] Epoch 8: Loss = 0.0039\n",
      "yes\n",
      "[mobilenet_v2] Epoch 9: Loss = 0.0038\n",
      "yes\n",
      "[mobilenet_v2] Epoch 10: Loss = 0.0033\n",
      "yes\n",
      "[mobilenet_v2] Epoch 11: Loss = 0.0030\n",
      "yes\n",
      "[mobilenet_v2] Epoch 12: Loss = 0.0027\n",
      "yes\n",
      "[mobilenet_v2] Epoch 13: Loss = 0.0026\n",
      "yes\n",
      "[mobilenet_v2] Epoch 14: Loss = 0.0024\n",
      "yes\n",
      "[mobilenet_v2] Epoch 15: Loss = 0.0024\n",
      "yes\n",
      "[mobilenet_v2] Epoch 16: Loss = 0.0021\n",
      "yes\n",
      "[mobilenet_v2] Epoch 17: Loss = 0.0022\n",
      "yes\n",
      "[mobilenet_v2] Epoch 18: Loss = 0.0020\n",
      "yes\n",
      "[mobilenet_v2] Epoch 19: Loss = 0.0019\n",
      "yes\n",
      "[mobilenet_v2] Epoch 20: Loss = 0.0018\n",
      "yes\n",
      "[mobilenet_v2] Epoch 21: Loss = 0.0019\n",
      "yes\n",
      "[mobilenet_v2] Epoch 22: Loss = 0.0016\n",
      "yes\n",
      "[mobilenet_v2] Epoch 23: Loss = 0.0016\n",
      "yes\n",
      "[mobilenet_v2] Epoch 24: Loss = 0.0015\n",
      "yes\n",
      "[mobilenet_v2] Epoch 25: Loss = 0.0014\n",
      "[mobilenet_v2] Test MSE (scaled): 0.0013\n",
      "ðŸ’¾ Saved model â†’ /Users/avanigupta/pm-estimation-from-images/models/mobilenet_v2_aqi.pth\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "\n",
    "    model = get_model(model_name).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # ---------- TRAIN ----------\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"yes\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"[{model_name}] Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "    # ---------- EVALUATE ----------\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"[{model_name}] Test MSE (scaled): {test_loss:.4f}\")\n",
    "\n",
    "    # Stack all batches\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    # Load scaler\n",
    "    scaler = joblib.load(\"/Users/avanigupta/pm-estimation-from-images/models/label_scaler.save\")\n",
    "\n",
    "    # Inverse transform\n",
    "    all_preds_unscaled = scaler.inverse_transform(all_preds)\n",
    "    all_labels_unscaled = scaler.inverse_transform(all_labels)\n",
    "\n",
    "    # ---------- SAVE MODEL ----------\n",
    "    model_path = os.path.join(save_dir, f\"{model_name}_aqi.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"ðŸ’¾ Saved model â†’ {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca9345",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
